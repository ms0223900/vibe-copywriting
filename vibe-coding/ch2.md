## 前言

### AI 在開發中的角色與潛力

生成式 AI 作為輔助生成的工具，像是 ChatGPT 或 Claude，都是以「聊天」的方式進行，提供 Prompt 給 AI，AI 會以「聊天」的方式回覆我們。

Prompt 之下得到的答案，很多很棒很驚艷，像是很多書本提到的原則與範例，有需多很棒的範例，拿來做文案、企劃生成是蠻不錯的方式。

AI 生成內容的隨機性既是優點也是缺點。這種「LLM 串接詞語的隨機性」讓每次產出都充滿驚喜，特別適合創意發想階段，能突破人類思維的框架限制。然而在技術開發領域，這種不穩定性就成為致命傷。拿來做創意性質的內容，像是文案、企劃是蠻不錯的方式，但拿來做技術開發，就會遇到蠻大的瓶頸。

這邊舉幾個例子：

- 技術文件
第一次，提供的具體指令：
```

```


第二次，提供如此指令：
```

```


- 
```

```

- 程式碼

```

```

雖然每次的回覆乍看之下都不錯，但結果不盡滿意，


## Vibe Coding 的流程

首先是建立原則，想方設法讓 AI 產出的內容更符合我們的期望，首要的目的是「穩定性」，其次是「品質」。

而這些問題主要在於 LLM 的「幻想問題」(Hallucination)：
1. **技術準確性**：AI 可能生成看似合理但實際上錯誤的技術內容，這是因為 LLM 的訓練資料包含了大量的網路資料，這些資料可能包含錯誤、過時的資訊，而 LLM 會「自信地」呈現這些不準確的資訊。
2. **一致性缺失**：相同 prompt 在不同時間可能產出不同結果
3. **上下文斷裂**：長對話中可能遺忘或扭曲先前討論的脈絡細節，

這種特性使得：
- 技術文件可能包含不準確的 API 用法
- 程式碼範例可能有隱藏的邏輯錯誤
- 系統架構建議可能忽略關鍵限制條件

更棘手的是，AI 通常會「自信地」呈現這些不準確的資訊，讓初學者難以辨別真偽。這正是為什麼在專業開發中，我們需要建立「Prompt 品質控制」機制，而非完全依賴 AI 的原始輸出。

### 設定 Prompt

### 產出程式碼

### 測試與調整

