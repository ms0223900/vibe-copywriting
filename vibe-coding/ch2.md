## 前言

### AI 在開發中的角色與潛力

生成式 AI 作為輔助生成的工具，像是 ChatGPT 或 Claude，都是以「聊天」的方式進行，提供 Prompt 給 AI，AI 會以「聊天」的方式回覆我們。

Prompt 之下得到的答案，很多很棒很驚艷，像是很多書本提到的原則與範例，有需多很棒的範例，拿來做文案、企劃生成是蠻不錯的方式。

AI 生成內容的隨機性既是優點也是缺點。這種「LLM 串接詞語的隨機性」讓每次產出都充滿驚喜，特別適合創意發想階段，能突破人類思維的框架限制。然而在技術開發領域，這種不穩定性就成為致命傷。拿來做創意性質的內容，像是文案、企劃是蠻不錯的方式，但拿來做技術開發，就會遇到蠻大的瓶頸，至於瓶頸在哪，我們後面再談。

這邊先看幾個 AI 輔助開發的「優良範例」：

比方說，以下是這次新增的 API 程式碼，我希望可以請 AI 幫我產出一份技術文件：

```
const express = require('express');
const router = express.Router();

// 模擬資料庫中的電子郵件資料
const emails = [
  { id: 1, subject: '歡迎信', from: 'service@example.com' },
  { id: 2, subject: '訂單確認', from: 'orders@example.com' },
  { id: 3, subject: '促銷活動', from: 'marketing@example.com' }
];

router.get('/emails', (req, res) => {
  try {
    // 回傳電子郵件清單
    res.status(200).json({
      success: true,
      data: emails
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      message: '取得郵件清單時發生錯誤'
    });
  }
});
module.exports = router;
```

- 技術文件：第一次，提供粗略的指令，我希望 AI 「自由發揮」，產出一份技術文件：

```
請 AI 幫我根據此 API 程式碼產出一份技術文件：
```

產出結果
```
以下是根据提供的 API 代码生成的技術文件，使用 Markdown 格式呈現：

---

# API 技術文件：電子郵件清單

## 概述
此 API 提供一個簡單的端點，用於獲取模擬的電子郵件清單。它基於 Express.js 框架，並以 JSON 格式返回資料。

## 端點
- **路徑**: `/emails`
- **方法**: `GET`

## 請求範例
```bash
curl -X GET http://yourdomain.com/emails
```

## 參數
此端點無需任何查詢參數或請求體。

### 關鍵功能
1. **模擬資料庫**:
   - 使用一個靜態陣列 `emails` 模擬資料庫中的電子郵件資料。
2. **錯誤處理**:
   - 使用 `try-catch` 區塊捕獲可能的錯誤，並返回適當的錯誤訊息。

## 使用情境
- 適用於需要快速獲取電子郵件清單的前端應用。
- 可用於測試或原型開發階段。

## 注意事項
- 此 API 僅為範例，實際應用中應替換為真實的資料庫查詢邏輯。
- 錯誤處理部分可根據需求進一步擴展，例如記錄錯誤日誌或發送警報。

--- [以上可以補上 Prompt 截圖]

總的來說，AI 產這樣很棒了！ 雖然不盡完美，但有總比沒有好。可以省下很多「行政作業」時間，而且產出的內容也蠻不錯，至少是一份蠻完整的 API 技術文件，應有盡有。

第二次，也是提供一樣的 Prompt 指令，得到這樣的答案：
```
以下是根据提供的 API 代码生成的技術文件，使用 Markdown 格式呈現：

---

# API 技術文件：電子郵件清單

## 概述  
此 API 提供一個簡單的端點，用於獲取模擬的電子郵件清單。它基於 Express.js 框架，並以 JSON 格式返回資料。

## 端點  
- **路徑**: `/emails`  
- **方法**: `GET`  

## 請求範例  
```bash
curl -X GET http://yourdomain.com/emails
```

## 參數  
此端點無需任何查詢參數或請求體。

## 關鍵功能  
1. **模擬資料庫**:  
   - 使用一個靜態陣列 `emails` 模擬資料庫中的電子郵件資料。  
2. **錯誤處理**:  
   - 使用 `try-catch` 區塊捕獲可能的錯誤，並返回適當的錯誤訊息。  

## 使用情境  
- 適用於需要快速獲取電子郵件清單的前端應用。  
- 可用於測試或原型開發階段。  

## 注意事項  
- 此 API 僅為範例，實際應用中應替換為真實的資料庫查詢邏輯。  
- 錯誤處理部分可根據需求進一步擴展，例如記錄錯誤日誌或發送警報。  

---

### 補充說明  
- **資料格式**:  
  返回的資料格式為 JSON，包含以下欄位：  
  - `success`: 布林值，表示請求是否成功。  
  - `data`: 電子郵件清單的陣列，每封郵件包含 `id`、`subject` 和 `from` 欄位。  
  - `message` (錯誤時): 錯誤訊息。  

- **擴展建議**:  
  - 若需支援分頁或篩選功能，可新增查詢參數（如 `limit`、`offset` 或 `subject`）。  
  - 考慮加入身份驗證機制（如 JWT）以保護端點。  

如果需要進一步調整或補充內容，請隨時告知！

---

這兩次的回覆乍看之下都不錯，但仔細看會發現，第二次的回覆比較完整，而且更符合我們的期望。而如果每次都要手動調整，這樣的效率太低了，所以這邊我們需要建立一個「Prompt 品質控制」機制，讓 AI 產出的內容更符合我們的期望。
讓生成的內容變成「可控」的，這樣我們就可以更有效地使用 AI 來輔助我們的開發工作。


## Vibe Coding 的流程

### 前言 -- AI 生成程式碼的品質控制

那麼，Vibe Coding 的流程是怎麼樣呢？

剛剛提到，我們需要建立一個「Prompt 品質控制」機制，讓 AI 產出的內容更符合我們的期望。而這又跟我們的主題「Vibe Coding」的流程有什麼關係？

當然有關係，雖然我們可以預期 AI 產出的程式碼「每次」都不太一樣，但至少要維持在一定的品質。這有點像是請不同同事寫程式碼，雖然每個同事寫的程式碼，實作細節都不太一樣，但至少都會要求在一定的品質。否則 Code Review 的時候，就會被打槍。

而當 AI 產出程式碼後，由提交 Prompt 的開發者需擔任第一道品質把關者。這包含一些基本的檢查，像是：

1. **技術正確性驗證**：檢查程式碼是否符合預期功能，特別注意邊界條件和效能考量，是不是 AI 生成的程式碼有符合目前專案的技術要求。
2. **風格一致性審查**：確保符合團隊的 coding style 和架構模式，這邊包含像是命名規則、程式碼風格、架構模式等。
3. **上下文適配性**：確認產出內容與當前專案需求相符，生成的程式碼是否有跟專案的脈絡 domain know how 相符。

這過程類似 Code Review，但更專注於「Prompt 與產出」的對應關係。如果每次生成品質參差不齊，我們開發者需要建立個檢查清單，例如：
- 是否正確實現了需求？
- 是否有潛在的效能瓶頸？
- 是否符合安全規範？

雖然透過這種機制，我們能逐步建立「可預期的 AI 協作模式」，讓 AI 成為更可靠。但每次都要這樣「人工」檢查，實在太累了、效率太低了！

因此，我們會希望 AI 能夠自動控管品質，可以產出「我們腦中預想的」內容，然而如同上述所說，AI 產出的內容，常常會跟我們預想的有所出入，這邊再舉個比較簡單且具體的範例。

我希望 AI 幫我實作 Fibonnaci 數列，但 AI 產出的內容，可能是實作出 Fibonnaci 數列的遞迴版本，而非更好的迴圈＋記憶版本。
或者，又像是上一章節提到的產出 API 技術文件，如果每次下指令產出的結果不一致，都還要手動調整，光想就很累呀。

說了這麼多，我們到底要怎麼辦？
所以我們需要建立一個「Prompt 品質控制」機制，讓 AI 產出的內容更符合我們的期望。

### 設定 Prompt 原則

首先是建立原則，想方設法讓 AI 產出的內容更符合我們的期望，首要的目的是「穩定性」。

而我們要先認識到，為什麼 AI 產出的內容會有這些問題呢？ 主要在於 LLM 的「幻想問題」(Hallucination)：

1. **技術準確性**：AI 可能生成看似合理但實際上錯誤的技術內容，這是因為 LLM 的訓練資料包含了大量的網路資料，這些資料可能包含錯誤、過時的資訊，而 LLM 會「自信地」呈現這些不準確的資訊。
2. **一致性缺失**：相同 prompt 在不同時間可能產出不同結果
3. **上下文斷裂**：長對話中可能遺忘或扭曲先前討論的脈絡細節，導致後續的回答不一致。

有沒有發現，這些問題其實跟我們在開發中遇到的問題很相似？ 沒錯，就是因為目前 LLM 技術上的「限制」，導致這些問題的發生，讓我們不得不面對這些問題，以提高生成的品質與穩定。

這種特性使得：
- 技術文件可能包含不準確的 API 用法
- 程式碼範例可能有隱藏的邏輯錯誤
- 系統架構建議可能忽略關鍵限制條件

更棘手的是，AI 通常會「自信地」呈現這些不準確的資訊，讓初學者難以辨別真偽。這正是為什麼在專業開發中，我們需要建立「Prompt 品質控制」機制，而非完全依賴 AI 的原始輸出。

...

### 設定 Prompt 原則




### 產出程式碼

### 測試與調整

